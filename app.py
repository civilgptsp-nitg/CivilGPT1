import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import json
import re
import traceback
from io import BytesIO
from difflib import get_close_matches
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from reportlab.lib import colors
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib.units import inch

# ==============================================================================
# PART 1: BACKEND LOGIC & HELPERS
# ==============================================================================

# Groq client
try:
    from groq import Groq
    client = Groq(api_key=st.secrets.get("GROQ_API_KEY", None))
except Exception:
    client = None

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))

# --- Column Normalization Maps ---
EMISSIONS_COL_MAP = {
    "material": "Material",
    "co2_factor_kg_co2_per_kg": "CO2_Factor(kg_CO2_per_kg)",
    "co2_factor": "CO2_Factor(kg_CO2_per_kg)",
    "co2factor": "CO2_Factor(kg_CO2_per_kg)",
    "emission_factor": "CO2_Factor(kg_CO2_per_kg)",
    "co2factor_kgco2perkg": "CO2_Factor(kg_CO2_per_kg)",
    "co2": "CO2_Factor(kg_CO2_per_kg)"
}
COSTS_COL_MAP = {
    "material": "Material",
    "cost_kg": "Cost(₹/kg)",
    "cost_rs_kg": "Cost(₹/kg)",
    "cost": "Cost(₹/kg)",
    "cost_per_kg": "Cost(₹/kg)",
    "costperkg": "Cost(₹/kg)",
    "price": "Cost(₹/kg)",
    "kg": "Cost(₹/kg)",
    "rs_kg": "Cost(₹/kg)",
    "costper": "Cost(₹/kg)",
    "price_kg": "Cost(₹/kg)",
    "priceperkg": "Cost(₹/kg)",
}
MATERIALS_COL_MAP = {
    "material": "Material",
    "specificgravity": "SpecificGravity",
    "specific_gravity": "SpecificGravity",
    "moisturecontent": "MoistureContent",
    "moisture_content": "MoistureContent",
    "waterabsorption": "WaterAbsorption",
    "water_absorption": "WaterAbsorption"
}

# --- Normalization Helpers ---
def _normalize_header(header):
    """Converts a messy header to a clean, underscore-based slug."""
    s = str(header).strip().lower()
    s = re.sub(r'[ \-/\.\(\)]+', '_', s)
    s = re.sub(r'[^a-z0-9_]+', '', s)
    s = re.sub(r'_+', '_', s)
    return s.strip('_')

def _normalize_material_value(s: str) -> str:
    """Normalize material name value to canonical slug for matching."""
    if s is None:
        return ""
    s = str(s).strip().lower()
    s = re.sub(r'\b(\d+mm)\b', r'\1', s)
    s = re.sub(r'[^a-z0-9\s]', ' ', s)
    s = re.sub(r'\s+', ' ', s).strip()
    s = s.replace('mm', '').strip()
    
    synonyms = {
        "m sand": "fine aggregate",
        "msand": "fine aggregate",
        "m-sand": "fine aggregate",
        "fine aggregate": "fine aggregate",
        "sand": "fine aggregate",
        "20 coarse aggregate": "coarse aggregate",
        "20mm coarse aggregate": "coarse aggregate",
        "20 coarse": "coarse aggregate",
        "20": "coarse aggregate",
        "coarse aggregate": "coarse aggregate",
        "20mm": "coarse aggregate",
        "pce superplasticizer": "pce superplasticizer",
        "pce superplasticiser": "pce superplasticizer",
        "pce": "pce superplasticizer",
        "opc 43": "opc 43",
        "opc 53": "opc 53",
        "fly ash": "fly ash",
        "ggbs": "ggbs",
        "water": "water",
    }
    key = s
    if key in synonyms:
        return synonyms[key]
    
    cand = get_close_matches(key, list(synonyms.keys()), n=1, cutoff=0.78)
    if cand:
        return synonyms[cand[0]]
    
    key2 = re.sub(r'^\d+\s*', '', key)
    cand = get_close_matches(key2, list(synonyms.keys()), n=1, cutoff=0.78)
    if cand:
        return synonyms[cand[0]]
        
    return key

def _normalize_columns(df, column_map):
    """Normalizes DataFrame columns based on a map of {normalized_variant: canonical_name}."""
    canonical_cols = list(dict.fromkeys(column_map.values()))
    if df is None or df.empty:
        return pd.DataFrame(columns=canonical_cols)

    df = df.copy()
    norm_cols = {}
    for col in df.columns:
        norm_col = _normalize_header(col)
        if norm_col not in norm_cols:
            norm_cols[norm_col] = col
    
    rename_dict = {}
    for variant, canonical in column_map.items():
        if variant in norm_cols:
            original_col_name = norm_cols[variant]
            if canonical not in rename_dict.values():
                rename_dict[original_col_name] = canonical

    df = df.rename(columns=rename_dict)
    found_canonical = [col for col in canonical_cols if col in df.columns]
    return df[found_canonical]

def _minmax_scale(series: pd.Series) -> pd.Series:
    """Performs min-max normalization on a pandas Series."""
    min_val = series.min()
    max_val = series.max()
    if pd.isna(min_val) or pd.isna(max_val) or (max_val - min_val) == 0:
        return pd.Series(0.0, index=series.index, dtype=float)
    return (series - min_val) / (max_val - min_val)

# --- IS Code Rules & Tables (IS 456 & IS 10262) ---
EXPOSURE_WB_LIMITS = {"Mild": 0.60,"Moderate": 0.55,"Severe": 0.50,"Very Severe": 0.45,"Marine": 0.40}
EXPOSURE_MIN_CEMENT = {"Mild": 300, "Moderate": 300, "Severe": 320,"Very Severe": 340, "Marine": 360}
EXPOSURE_MIN_GRADE = {"Mild": "M20", "Moderate": "M25", "Severe": "M30","Very Severe": "M35", "Marine": "M40"}
GRADE_STRENGTH = {"M10": 10, "M15": 15, "M20": 20, "M25": 25,"M30": 30, "M35": 35, "M40": 40, "M45": 45, "M50": 50}
WATER_BASELINE = {10: 208, 12.5: 202, 20: 186, 40: 165} # IS 10262, Table 4 (for 50mm slump)
AGG_SHAPE_WATER_ADJ = {"Angular (baseline)": 0.00, "Sub-angular": -0.03,"Sub-rounded": -0.05, "Rounded": -0.07,"Flaky/Elongated": +0.03}
QC_STDDEV = {"Good": 5.0, "Fair": 7.5, "Poor": 10.0} # IS 10262, Table 2
ENTRAPPED_AIR_VOL = {10: 0.02, 12.5: 0.015, 20: 0.01, 40: 0.008} # m³ per m³ of concrete
BINDER_RANGES = {
    "M10": (220, 320), "M15": (250, 350), "M20": (300, 400),
    "M25": (320, 420), "M30": (340, 450), "M35": (360, 480),
    "M40": (380, 500), "M45": (400, 520), "M50": (420, 540)
}
COARSE_AGG_FRAC_BY_ZONE = {
    10: {"Zone I": 0.50, "Zone II": 0.48, "Zone III": 0.46, "Zone IV": 0.44},
    12.5: {"Zone I": 0.59, "Zone II": 0.57, "Zone III": 0.55, "Zone IV": 0.53},
    20: {"Zone I": 0.66, "Zone II": 0.64, "Zone III": 0.62, "Zone IV": 0.60},
    40: {"Zone I": 0.71, "Zone II": 0.69, "Zone III": 0.67, "Zone IV": 0.65}
}
FINE_AGG_ZONE_LIMITS = {
    "Zone I":   {"10.0": (100,100),"4.75": (90,100),"2.36": (60,95),"1.18": (30,70),"0.600": (15,34),"0.300": (5,20),"0.150": (0,10)},
    "Zone II":  {"10.0": (100,100),"4.75": (90,100),"2.36": (75,100),"1.18": (55,90),"0.600": (35,59),"0.300": (8,30),"0.150": (0,10)},
    "Zone III": {"10.0": (100,100),"4.75": (90,100),"2.36": (85,100),"1.18": (75,90),"0.600": (60,79),"0.300": (12,40),"0.150": (0,10)},
    "Zone IV":  {"10.0": (95,100),"4.75": (95,100),"2.36": (95,100),"1.18": (90,100),"0.600": (80,100),"0.300": (15,50),"0.150": (0,15)},
}
COARSE_LIMITS = {
    10: {"20.0": (100,100), "10.0": (85,100),       "4.75": (0,20)},
    20: {"40.0": (95,100),  "20.0": (95,100),  "10.0": (25,55), "4.75": (0,10)},
    40: {"80.0": (95,100),  "40.0": (95,100),  "20.0": (30,70), "10.0": (0,15)}
}

# --- Purpose-Based Optimization Profiles & Helpers ---
PURPOSE_PROFILES = {
    "General": {
        "description": "A balanced, default mix. Follows IS code minimums without specific optimization bias.",
        "wb_limit": 1.0, "scm_limit": 0.5, "min_binder": 0.0,
        "weights": {"co2": 0.4, "cost": 0.4, "purpose": 0.2}
    },
    "Slab": {
        "description": "Prioritizes workability (slump) and cost-effectiveness. Strength is often not the primary driver.",
        "wb_limit": 0.55, "scm_limit": 0.5, "min_binder": 300,
        "weights": {"co2": 0.3, "cost": 0.5, "purpose": 0.2}
    },
    "Beam": {
        "description": "Prioritizes strength (modulus) and durability. Often heavily reinforced.",
        "wb_limit": 0.50, "scm_limit": 0.4, "min_binder": 320,
        "weights": {"co2": 0.4, "cost": 0.2, "purpose": 0.4}
    },
    "Column": {
        "description": "Prioritizes high compressive strength and durability. Congestion is common.",
        "wb_limit": 0.45, "scm_limit": 0.35, "min_binder": 340,
        "weights": {"co2": 0.3, "cost": 0.2, "purpose": 0.5}
    },
    "Pavement": {
        "description": "Prioritizes durability, flexural strength (fatigue), and abrasion resistance. Cost is a major factor.",
        "wb_limit": 0.45, "scm_limit": 0.4, "min_binder": 340,
        "weights": {"co2": 0.3, "cost": 0.4, "purpose": 0.3}
    },
    "Precast": {
        "description": "Prioritizes high early strength (for form stripping), surface finish, and cost (reproducibility).",
        "wb_limit": 0.45, "scm_limit": 0.3, "min_binder": 360,
        "weights": {"co2": 0.2, "cost": 0.5, "purpose": 0.3}
    }
}

def load_purpose_profiles(filepath=None):
    """Loads purpose profiles from a file or returns the in-code default."""
    if filepath and os.path.exists(filepath):
        try:
            st.info("Custom profile loading not yet implemented. Using defaults.")
            return PURPOSE_PROFILES
        except Exception as e:
            st.warning(f"Could not load or parse custom profiles: {e}. Falling back to defaults.")
            return PURPOSE_PROFILES
    return PURPOSE_PROFILES

def evaluate_purpose_specific_metrics(candidate_meta: dict, purpose: str) -> dict:
    """Calculates pragmatic, estimated engineering properties for a mix."""
    try:
        fck_target = float(candidate_meta.get('fck_target', 30.0))
        wb = float(candidate_meta.get('w_b', 0.5))
        binder = float(candidate_meta.get('cementitious', 350.0))
        water = float(candidate_meta.get('water_target', 180.0))
        
        modulus_proxy = 5000 * np.sqrt(fck_target)
        shrinkage_risk_index = (binder * water) / 10000.0
        fatigue_proxy = (1.0 - wb) * (binder / 1000.0)

        return {
            "estimated_modulus_proxy (MPa)": round(modulus_proxy, 0),
            "shrinkage_risk_index": round(shrinkage_risk_index, 2),
            "pavement_fatigue_proxy": round(fatigue_proxy, 2)
        }
    except Exception:
        return {
            "estimated_modulus_proxy (MPa)": None,
            "shrinkage_risk_index": None,
            "pavement_fatigue_proxy": None
        }

def compute_purpose_penalty(candidate_meta: dict, purpose_profile: dict) -> float:
    """Computes a penalty score for a mix based on its deviation from the ideal 'purpose_profile'."""
    if not purpose_profile:
        return 0.0
    penalty = 0.0
    try:
        wb_limit = purpose_profile.get('wb_limit', 1.0)
        current_wb = candidate_meta.get('w_b', 0.5)
        if current_wb > wb_limit:
            penalty += (current_wb - wb_limit) * 1000 

        scm_limit = purpose_profile.get('scm_limit', 0.5)
        current_scm = candidate_meta.get('scm_total_frac', 0.0)
        if current_scm > scm_limit:
            penalty += (current_scm - scm_limit) * 100

        min_binder = purpose_profile.get('min_binder', 0.0)
        current_binder = candidate_meta.get('cementitious', 300.0)
        if current_binder < min_binder:
            penalty += (min_binder - current_binder) * 0.1
            
        return float(max(0.0, penalty))
    except Exception:
        return 0.0

# --- Dataset Path Handling & Loading ---
LAB_FILE = "lab_processed_mgrades_only.xlsx"
MIX_FILE = "concrete_mix_design_data_cleaned_standardized.xlsx"

def safe_load_excel(name):
    paths_to_try = [
        os.path.join(SCRIPT_DIR, name),
        os.path.join(SCRIPT_DIR, "data", name)
    ]
    for p in paths_to_try:
        if os.path.exists(p):
            try:
                return pd.read_excel(p)
            except Exception:
                try:
                    return pd.read_excel(p, engine="openpyxl")
                except Exception:
                    st.warning(f"Failed to read Excel file at {p}")
                    return None
    return None

lab_df = safe_load_excel(LAB_FILE)
mix_df = safe_load_excel(MIX_FILE)

# --- Parsers ---
def simple_parse(text: str) -> dict:
    result = {}
    grade_match = re.search(r"\bM\s*(10|15|20|25|30|35|40|45|50)\b", text, re.IGNORECASE)
    if grade_match: result["grade"] = "M" + grade_match.group(1)
    for exp in EXPOSURE_WB_LIMITS.keys():
        if re.search(exp, text, re.IGNORECASE): result["exposure"] = exp; break
    slump_match = re.search(r"slump\s*(?:of\s*)?(\d{2,3})\s*mm", text, re.IGNORECASE)
    if slump_match: result["slump"] = int(slump_match.group(1))
    cement_types = ["OPC 43"]
    for ctype in cement_types:
        if re.search(ctype.replace(" ", r"\s*"), text, re.IGNORECASE):
            result["cement"] = ctype; break
    nom_match = re.search(r"(\d{2}(\.5)?)\s*mm", text, re.IGNORECASE)
    if nom_match:
        try: result["nom_max"] = float(nom_match.group(1))
        except: pass
    return result

def parse_input_with_llm(user_text: str) -> dict:
    if client is None:
        return simple_parse(user_text)
    prompt = f"Extract grade, exposure, slump (mm), cement type, and nominal max aggregate from: {user_text}. Return JSON."
    resp = client.chat.completions.create(
        model="mixtral-8x7b-32768",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.0,
    )
    try:
        parsed = json.loads(resp.choices[0].message.content)
    except Exception:
        parsed = simple_parse(user_text)
    return parsed

# --- Data Loading & General Helpers ---
@st.cache_data
def _read_csv_try(path): return pd.read_csv(path)

@st.cache_data
def load_data(materials_file=None, emissions_file=None, cost_file=None):
    """Loads materials, emissions, and cost data, normalizes columns, and handles errors."""
    def _safe_read(file, default):
        if file is not None:
            try:
                if hasattr(file, 'seek'):
                    file.seek(0)
                return pd.read_csv(file)
            except Exception as e:
                st.warning(f"Could not read uploaded file {file.name}: {e}")
                return default
        return default

    def _load_fallback(default_names):
        paths_to_try = [
            os.path.join(SCRIPT_DIR, default_names[0]),
            os.path.join(SCRIPT_DIR, default_names[1])
        ]
        for p in paths_to_try:
            if os.path.exists(p):
                try:
                    return pd.read_csv(p)
                except Exception as e:
                    st.warning(f"Could not read {p}: {e}")
        return None

    materials = _safe_read(materials_file, _load_fallback(["materials_library.csv", "data/materials_library.csv"]))
    emissions = _safe_read(emissions_file, _load_fallback(["emission_factors.csv", "data/emission_factors.csv"]))
    costs = _safe_read(cost_file, _load_fallback(["cost_factors.csv", "data/cost_factors.csv"]))

    materials = _normalize_columns(materials, MATERIALS_COL_MAP)
    if "Material" in materials.columns:
        materials["Material"] = materials["Material"].astype(str).str.strip()
    if materials.empty or "Material" not in materials.columns:
        st.warning("Could not load 'materials_library.csv' or 'Material' column not found. Using empty library.", icon="ℹ️")
        materials = pd.DataFrame(columns=list(dict.fromkeys(MATERIALS_COL_MAP.values())))

    emissions = _normalize_columns(emissions, EMISSIONS_COL_MAP)
    if "Material" in emissions.columns:
        emissions["Material"] = emissions["Material"].astype(str).str.strip()
    if emissions.empty or "Material" not in emissions.columns or "CO2_Factor(kg_CO2_per_kg)" not in emissions.columns:
        st.warning("⚠️ Could not load 'emission_factors.csv' or required columns ('Material', 'CO2_Factor') not found. CO2 calculations will be zero.")
        emissions = pd.DataFrame(columns=list(dict.fromkeys(EMISSIONS_COL_MAP.values())))
        
    costs = _normalize_columns(costs, COSTS_COL_MAP)
    if "Material" in costs.columns:
        costs["Material"] = costs["Material"].astype(str).str.strip()
    if costs.empty or "Material" not in costs.columns or "Cost(₹/kg)" not in costs.columns:
        st.warning("⚠️ Could not load 'cost_factors.csv' or required columns ('Material', 'Cost') not found. Cost calculations will be zero.")
        costs = pd.DataFrame(columns=list(dict.fromkeys(COSTS_COL_MAP.values())))

    return materials, emissions, costs

def pareto_front(df, x_col="cost", y_col="co2"):
    if df.empty:
        return pd.DataFrame(columns=df.columns)
    sorted_df = df.sort_values(by=[x_col, y_col], ascending=[True, True])
    pareto_points = []
    last_y = float('inf')
    for _, row in sorted_df.iterrows():
        if row[y_col] < last_y:
            pareto_points.append(row)
            last_y = row[y_col]
    if not pareto_points:
        return pd.DataFrame(columns=df.columns)
    return pd.DataFrame(pareto_points).reset_index(drop=True)

def water_for_slump_and_shape(nom_max_mm: int, slump_mm: int,
                            agg_shape: str, uses_sp: bool=False,
                            sp_reduction_frac: float=0.0) -> float:
    base = WATER_BASELINE.get(int(nom_max_mm), 186.0)
    if slump_mm <= 50: water = base
    else: water = base * (1 + 0.03 * ((slump_mm - 50) / 25.0))
    water *= (1.0 + AGG_SHAPE_WATER_ADJ.get(agg_shape, 0.0))
    if uses_sp and sp_reduction_frac > 0: water *= (1 - sp_reduction_frac)
    return float(water)

def reasonable_binder_range(grade: str):
    return BINDER_RANGES.get(grade, (300, 500))

def get_coarse_agg_fraction(nom_max_mm: float, fa_zone: str, wb_ratio: float):
    base_fraction = COARSE_AGG_FRAC_BY_ZONE.get(nom_max_mm, {}).get(fa_zone, 0.62)
    wb_diff = 0.50 - wb_ratio
    correction = (wb_diff / 0.05) * 0.01
    corrected_fraction = base_fraction + correction
    return max(0.4, min(0.8, corrected_fraction))

def run_lab_calibration(lab_df):
    results = []
    default_qc_level = "Good"
    std_dev_S = QC_STDDEV[default_qc_level]
    for _, row in lab_df.iterrows():
        try:
            grade = str(row['grade']).strip()
            actual_strength = float(row['actual_strength'])
            if grade not in GRADE_STRENGTH:
                continue
            fck = GRADE_STRENGTH[grade]
            predicted_strength = fck + 1.65 * std_dev_S
            results.append({
                "Grade": grade,
                "Exposure": row.get('exposure', 'N/A'),
                "Slump (mm)": row.get('slump', 'N/A'),
                "Lab Strength (MPa)": actual_strength,
                "Predicted Target Strength (MPa)": predicted_strength,
                "Error (MPa)": predicted_strength - actual_strength
            })
        except (KeyError, ValueError, TypeError):
            pass
    if not results:
        return None, {}
    results_df = pd.DataFrame(results)
    mae = results_df["Error (MPa)"].abs().mean()
    rmse = np.sqrt((results_df["Error (MPa)"] ** 2).mean())
    bias = results_df["Error (MPa)"].mean()
    metrics = {"Mean Absolute Error (MPa)": mae, "Root Mean Squared Error (MPa)": rmse, "Mean Bias (MPa)": bias}
    return results_df, metrics

# ==============================================================================
# PART 2: CORE MIX LOGIC
# ==============================================================================

def evaluate_mix(components_dict, emissions_df, costs_df=None):
    """Calculates CO2 and Cost for a given mix, with robust merging and warnings."""
    comp_items = [(m.strip(), q) for m, q in components_dict.items() if q > 0.01]
    comp_df = pd.DataFrame(comp_items, columns=["Material", "Quantity (kg/m3)"])
    comp_df["Material_norm"] = comp_df["Material"].apply(_normalize_material_value)
    
    # --- CO2 Calculation ---
    if emissions_df is not None and not emissions_df.empty and "CO2_Factor(kg_CO2_per_kg)" in emissions_df.columns:
        emissions_df_norm = emissions_df.copy()
        emissions_df_norm['Material'] = emissions_df_norm['Material'].astype(str)
        emissions_df_norm["Material_norm"] = emissions_df_norm["Material"].apply(_normalize_material_value)
        emissions_df_norm = emissions_df_norm.drop_duplicates(subset=["Material_norm"])
        
        df = comp_df.merge(emissions_df_norm[["Material_norm","CO2_Factor(kg_CO2_per_kg)"]],
                            on="Material_norm", how="left")
        
        missing_rows = df[df["CO2_Factor(kg_CO2_per_kg)"].isna()]
        missing_emissions = [m for m in missing_rows["Material"].tolist() if m and str(m).strip()]
        
        if missing_emissions:
            if 'warned_emissions' not in st.session_state:
                st.session_state.warned_emissions = set()
            new_missing = set(missing_emissions) - st.session_state.warned_emissions
            if new_missing:
                st.warning(f"No emission factors found for: {', '.join(list(new_missing))}. CO2 will be 0 for these materials.", icon="⚠️")
                st.session_state.warned_emissions.update(new_missing)
        
        df["CO2_Factor(kg_CO2_per_kg)"] = df["CO2_Factor(kg_CO2_per_kg)"].fillna(0.0)
    else:
        df = comp_df.copy()
        df["CO2_Factor(kg_CO2_per_kg)"] = 0.0
        
    df["CO2_Emissions (kg/m3)"] = df["Quantity (kg/m3)"] * df["CO2_Factor(kg_CO2_per_kg)"]

    # --- Cost Calculation ---
    if costs_df is not None and not costs_df.empty and "Cost(₹/kg)" in costs_df.columns:
        costs_df_norm = costs_df.copy()
        costs_df_norm['Material'] = costs_df_norm['Material'].astype(str)
        costs_df_norm["Material_norm"] = costs_df_norm["Material"].apply(_normalize_material_value)
        costs_df_norm = costs_df_norm.drop_duplicates(subset=["Material_norm"])
        
        df = df.merge(costs_df_norm[["Material_norm", "Cost(₹/kg)"]], on="Material_norm", how="left")
        
        missing_rows_cost = df[df["Cost(₹/kg)"].isna()]
        missing_costs = [m for m in missing_rows_cost["Material"].tolist() if m and str(m).strip()]
        
        if missing_costs:
            if 'warned_costs' not in st.session_state:
                st.session_state.warned_costs = set()
            new_missing = set(missing_costs) - st.session_state.warned_costs
            if new_missing:
                st.warning(f"No cost factors found for: {', '.join(list(new_missing))}. Cost will be 0 for these materials.", icon="⚠️")
                st.session_state.warned_costs.update(new_missing)
                
        df["Cost(₹/kg)"] = df["Cost(₹/kg)"].fillna(0.0)
    else:
        df["Cost(₹/kg)"] = 0.0
        
    df["Cost (₹/m3)"] = df["Quantity (kg/m3)"] * df["Cost(₹/kg)"]
    
    # --- Final Formatting ---
    df["Material"] = df["Material"].str.title()
    
    for col in ["Material","Quantity (kg/m3)","CO2_Factor(kg_CO2_per_kg)","CO2_Emissions (kg/m3)","Cost(₹/kg)","Cost (₹/m3)"]:
        if col not in df.columns:
            df[col] = 0.0 if "kg" in col or "m3" in col else ""
            
    return df[["Material","Quantity (kg/m3)","CO2_Factor(kg_CO2_per_kg)","CO2_Emissions (kg/m3)","Cost(₹/kg)","Cost (₹/m3)"]]

def aggregate_correction(delta_moisture_pct: float, agg_mass_ssd: float):
    water_delta = (delta_moisture_pct / 100.0) * agg_mass_ssd
    corrected_mass = agg_mass_ssd * (1 + delta_moisture_pct / 100.0)
    return float(water_delta), float(corrected_mass)

def compute_aggregates(cementitious, water, sp, coarse_agg_fraction,
                       nom_max_mm, 
                       density_fa=2650.0, density_ca=2700.0):
    """Computes aggregate volumes and masses based on absolute volume method, including entrapped air."""
    vol_cem = cementitious / 3150.0
    vol_wat = water / 1000.0
    vol_sp  = sp / 1200.0
    
    vol_air = ENTRAPPED_AIR_VOL.get(int(nom_max_mm), 0.01)
    
    vol_paste_and_air = vol_cem + vol_wat + vol_sp + vol_air
    vol_agg = 1.0 - vol_paste_and_air
    
    if vol_agg <= 0: 
        vol_agg = 0.60
    
    vol_coarse = vol_agg * coarse_agg_fraction
    vol_fine = vol_agg * (1.0 - coarse_agg_fraction)

    mass_fine_ssd = vol_fine * density_fa
    mass_coarse_ssd = vol_coarse * density_ca
    
    return float(mass_fine_ssd), float(mass_coarse_ssd)

def compliance_checks(mix_df, meta, exposure):
    checks = {}
    try: checks["W/B ≤ exposure limit"] = float(meta["w_b"]) <= EXPOSURE_WB_LIMITS[exposure]
    except: checks["W/B ≤ exposure limit"] = False
    try: checks["Min cementitious met"] = float(meta["cementitious"]) >= float(EXPOSURE_MIN_CEMENT[exposure])
    except: checks["Min cementitious met"] = False
    try: checks["SCM ≤ 50%"] = float(meta.get("scm_total_frac", 0.0)) <= 0.50
    except: checks["SCM ≤ 50%"] = False
    try:
        total_mass = float(mix_df["Quantity (kg/m3)"].sum())
        checks["Unit weight 2200–2600 kg/m³"] = 2200.0 <= total_mass <= 2600.0
    except: checks["Unit weight 2200–2600 kg/m³"] = False
    derived = {
        "w/b used": round(float(meta.get("w_b", 0.0)), 3),
        "cementitious (kg/m³)": round(float(meta.get("cementitious", 0.0)), 1),
        "SCM % of cementitious": round(100 * float(meta.get("scm_total_frac", 0.0)), 1),
        "total mass (kg/m³)": round(float(mix_df["Quantity (kg/m3)"].sum()), 1) if "Quantity (kg/m3)" in mix_df.columns else None,
        "water target (kg/m³)": round(float(meta.get("water_target", 0.0)), 1),
        "cement (kg/m³)": round(float(meta.get("cement", 0.0)), 1),
        "fly ash (kg/m³)": round(float(meta.get("flyash", 0.0)), 1),
        "GGBS (kg/m³)": round(float(meta.get("ggbs", 0.0)), 1),
        "fine agg (kg/m³)": round(float(meta.get("fine", 0.0)), 1),
        "coarse agg (kg/m³)": round(float(meta.get("coarse", 0.0)), 1),
        "SP (kg/m³)": round(float(meta.get("sp", 0.0)), 2),
        "fck (MPa)": meta.get("fck"), "fck,target (MPa)": meta.get("fck_target"), "QC (S, MPa)": meta.get("stddev_S"),
    }
    if "purpose" in meta and meta["purpose"] != "General":
        derived["purpose"] = meta["purpose"]
        derived["purpose_penalty"] = meta.get("purpose_penalty")
        derived["composite_score"] = meta.get("composite_score")
        derived["purpose_metrics"] = meta.get("purpose_metrics")

    return checks, derived

def sanity_check_mix(meta, df):
    warnings = []
    try:
        cement, water, fine, coarse, sp = float(meta.get("cement", 0)), float(meta.get("water_target", 0)), float(meta.get("fine", 0)), float(meta.get("coarse", 0)), float(meta.get("sp", 0))
        unit_wt = float(df["Quantity (kg/m3)"].sum())
    except Exception: return ["Insufficient data to run sanity checks."]
    
    if cement > 500: warnings.append(f"High cement content ({cement:.1f} kg/m³). Increases cost, shrinkage, and CO₂.")
    if water < 140 or water > 220: warnings.append(f"Water content ({water:.1f} kg/m³) is outside the typical range of 140-220 kg/m³.")
    if fine < 500 or fine > 900: warnings.append(f"Fine aggregate quantity ({fine:.1f} kg/m³) is unusual.")
    if coarse < 1000 or coarse > 1300: warnings.append(f"Coarse aggregate quantity ({coarse:.1f} kg/m³) is unusual.")
    if sp > 20: warnings.append(f"Superplasticizer dosage ({sp:.1f} kg/m³) is unusually high.")
    return warnings

def check_feasibility(mix_df, meta, exposure):
    checks, derived = compliance_checks(mix_df, meta, exposure)
    warnings = sanity_check_mix(meta, mix_df)
    reasons_fail = [f"IS Code Fail: {k}" for k, v in checks.items() if not v]
    feasible = len(reasons_fail) == 0
    return feasible, reasons_fail, warnings, derived, checks

def get_compliance_reasons(mix_df, meta, exposure):
    reasons = []
    try:
        limit = EXPOSURE_WB_LIMITS[exposure]
        used = float(meta["w_b"])
        if used > limit:
            reasons.append(f"Failed W/B ratio limit ({used:.3f} > {limit:.2f})")
    except: reasons.append("Failed W/B ratio check (parsing error)")
    try:
        limit = float(EXPOSURE_MIN_CEMENT[exposure])
        used = float(meta["cementitious"])
        if used < limit:
            reasons.append(f"Cementitious below minimum ({used:.1f} kg/m³ < {limit:.1f} kg/m³)")
    except: reasons.append("Failed min. cementitious check (parsing error)")
    try:
        limit = 0.50
        used = float(meta.get("scm_total_frac", 0.0))
        if used > limit:
            reasons.append(f"SCM fraction exceeds limit ({used*100:.0f}% > {limit*100:.0f}%)")
    except: reasons.append("Failed SCM fraction check (parsing error)")
    try:
        min_limit, max_limit = 2200.0, 2600.0
        total_mass = float(mix_df["Quantity (kg/m3)"].sum())
        if not (min_limit <= total_mass <= max_limit):
            reasons.append(f"Unit weight outside range ({total_mass:.1f} kg/m³ not in {min_limit:.0f}-{max_limit:.0f} kg/m³)")
    except: reasons.append("Failed unit weight check (parsing error)")
    
    feasible = len(reasons) == 0
    if feasible:
        return feasible, "All IS-code checks passed."
    else:
        return feasible, "; ".join(reasons)

def sieve_check_fa(df: pd.DataFrame, zone: str):
    try:
        limits, ok, msgs = FINE_AGG_ZONE_LIMITS[zone], True, []
        for sieve, (lo, hi) in limits.items():
            row = df.loc[df["Sieve_mm"].astype(str) == sieve]
            if row.empty:
                ok = False; msgs.append(f"Missing sieve size: {sieve} mm."); continue
            p = float(row["PercentPassing"].iloc[0])
            if not (lo <= p <= hi): ok = False; msgs.append(f"Sieve {sieve} mm: {p:.1f}% passing is outside the required range of {lo}-{hi}%.")
        if ok: msgs = [f"Fine aggregate conforms to IS 383 for {zone}."]
        return ok, msgs
    except: return False, ["Invalid fine aggregate CSV format. Ensure 'Sieve_mm' and 'PercentPassing' columns exist."]

def sieve_check_ca(df: pd.DataFrame, nominal_mm: int):
    try:
        limits, ok, msgs = COARSE_LIMITS[int(nominal_mm)], True, []
        for sieve, (lo, hi) in limits.items():
            row = df.loc[df["Sieve_mm"].astype(str) == sieve]
            if row.empty:
                ok = False; msgs.append(f"Missing sieve size: {sieve} mm."); continue
            p = float(row["PercentPassing"].iloc[0])
            if not (lo <= p <= hi): ok = False; msgs.append(f"Sieve {sieve} mm: {p:.1f}% passing is outside the required range of {lo}-{hi}%.")
        if ok: msgs = [f"Coarse aggregate conforms to IS 383 for {nominal_mm} mm graded aggregate."]
        return ok, msgs
    except: return False, ["Invalid coarse aggregate CSV format. Ensure 'Sieve_mm' and 'PercentPassing' columns exist."]

def generate_mix(grade, exposure, nom_max, target_slump, agg_shape, fine_zone, 
                 emissions, costs, cement_choice, material_props, 
                 use_sp=True, sp_reduction=0.18, optimize_cost=False, 
                 wb_min=0.35, wb_steps=6, max_flyash_frac=0.3, max_ggbs_frac=0.5, 
                 scm_step=0.1, fine_fraction_override=None,
                 purpose='General', purpose_profile=None, purpose_weights=None,
                 enable_purpose_optimization=False):
    """
    Generates candidate mixes, performs two-stage optimization (IS-code check, then composite score).
    """
    w_b_limit, min_cem_exp = float(EXPOSURE_WB_LIMITS[exposure]), float(EXPOSURE_MIN_CEMENT[exposure])
    target_water = water_for_slump_and_shape(nom_max_mm=nom_max, slump_mm=int(target_slump), agg_shape=agg_shape, uses_sp=use_sp, sp_reduction_frac=sp_reduction)
    
    trace = []
    feasible_candidates = []

    wb_values = np.linspace(float(wb_min), float(w_b_limit), int(wb_steps))
    flyash_options = np.arange(0.0, max_flyash_frac + 1e-9, scm_step)
    ggbs_options = np.arange(0.0, max_ggbs_frac + 1e-9, scm_step)
    min_b_grade, max_b_grade = reasonable_binder_range(grade)

    if 'warned_emissions' in st.session_state:
        st.session_state.warned_emissions.clear()
    if 'warned_costs' in st.session_state:
        st.session_state.warned_costs.clear()
        
    if purpose_profile is None:
        purpose_profile = PURPOSE_PROFILES['General']
    if purpose_weights is None:
        purpose_weights = PURPOSE_PROFILES['General']['weights']

    # --- STAGE 1: Enumerate all candidates ---
    for wb in wb_values:
        for flyash_frac in flyash_options:
            for ggbs_frac in ggbs_options:
                if flyash_frac + ggbs_frac > 0.50: continue

                binder_for_strength = target_water / wb
                binder = max(binder_for_strength, min_cem_exp, min_b_grade)
                binder = min(binder, max_b_grade)
                actual_wb = target_water / binder

                cement, flyash, ggbs = binder * (1 - flyash_frac - ggbs_frac), binder * flyash_frac, binder * ggbs_frac
                sp = 0.01 * binder if use_sp else 0.0

                density_fa = material_props['sg_fa'] * 1000
                density_ca = material_props['sg_ca'] * 1000

                if fine_fraction_override is not None:
                    coarse_agg_frac = 1.0 - fine_fraction_override
                else:
                    coarse_agg_frac = get_coarse_agg_fraction(nom_max, fine_zone, actual_wb)

                fine_ssd, coarse_ssd = compute_aggregates(binder, target_water, sp, coarse_agg_frac, nom_max, density_fa, density_ca)

                water_delta_fa, fine_wet = aggregate_correction(material_props['moisture_fa'], fine_ssd)
                water_delta_ca, coarse_wet = aggregate_correction(material_props['moisture_ca'], coarse_ssd)

                water_to_remove = water_delta_fa + water_delta_ca
                water_final = target_water - water_to_remove
                if water_final < 5.0:
                    water_final = 5.0

                mix = {cement_choice: cement,"Fly Ash": flyash,"GGBS": ggbs,"Water": water_final,"PCE Superplasticizer": sp,"Fine Aggregate": fine_wet,"Coarse Aggregate": coarse_wet}
                df = evaluate_mix(mix, emissions, costs)
                
                co2_total = float(df["CO2_Emissions (kg/m3)"].sum())
                cost_total = float(df["Cost (₹/m3)"].sum())

                candidate_meta = {
                    "w_b": actual_wb, "cementitious": binder, "cement": cement, 
                    "flyash": flyash, "ggbs": ggbs, "water_target": target_water, 
                    "water_final": water_final, "sp": sp, "fine": fine_wet, 
                    "coarse": coarse_wet, "scm_total_frac": flyash_frac + ggbs_frac, 
                    "grade": grade, "exposure": exposure, "nom_max": nom_max, 
                    "slump": target_slump, 
                    "co2_total": co2_total,
                    "cost_total": cost_total,
                    "coarse_agg_fraction": coarse_agg_frac, 
                    "binder_range": (min_b_grade, max_b_grade), 
                    "material_props": material_props,
                    "df": df.copy()
                }
                
                purpose_metrics = evaluate_purpose_specific_metrics(candidate_meta, purpose)
                purpose_penalty = compute_purpose_penalty(candidate_meta, purpose_profile)
                
                candidate_meta["purpose"] = purpose
                candidate_meta["purpose_metrics"] = purpose_metrics
                candidate_meta["purpose_penalty"] = purpose_penalty

                feasible, _, _, _, _ = check_feasibility(df, candidate_meta, exposure)
                trace_feasible, trace_reasons = get_compliance_reasons(df, candidate_meta, exposure)
                
                score = co2_total if not optimize_cost else cost_total
                
                trace.append({
                    "wb": float(actual_wb), 
                    "flyash_frac": float(flyash_frac), 
                    "ggbs_frac": float(ggbs_frac),
                    "co2": float(co2_total),
                    "cost": float(cost_total),
                    "score": float(score),
                    "feasible": bool(trace_feasible),
                    "reasons": str(trace_reasons),
                    "purpose": purpose,
                    "purpose_penalty": float(purpose_penalty),
                    "composite_score": np.nan,
                    "norm_co2": np.nan,
                    "norm_cost": np.nan,
                    "norm_purpose": np.nan
                })
                
                if feasible:
                    feasible_candidates.append(candidate_meta)
                        
    # --- STAGE 2: Optimize and Select ---
    if not feasible_candidates:
        return None, None, trace

    feasible_df = pd.DataFrame(feasible_candidates)
    trace_df = pd.DataFrame(trace)
    best_meta = {}
    
    if not enable_purpose_optimization or purpose == 'General':
        # Backwards-compatible logic
        objective_col = 'cost_total' if optimize_cost else 'co2_total'
        best_idx = feasible_df[objective_col].idxmin()
        best_meta = feasible_df.loc[best_idx].to_dict()
        best_meta["composite_score"] = np.nan
    
    else:
        # New Composite Score logic
        feasible_df['norm_co2'] = _minmax_scale(feasible_df['co2_total'])
        feasible_df['norm_cost'] = _minmax_scale(feasible_df['cost_total'])
        feasible_df['norm_purpose'] = _minmax_scale(feasible_df['purpose_penalty'])
        
        w_co2 = purpose_weights.get('w_co2', 0.4)
        w_cost = purpose_weights.get('w_cost', 0.4)
        w_purpose = purpose_weights.get('w_purpose', 0.2)
        
        feasible_df['composite_score'] = (
            w_co2 * feasible_df['norm_co2'] +
            w_cost * feasible_df['norm_cost'] +
            w_purpose * feasible_df['norm_purpose']
        )
        
        best_idx = feasible_df['composite_score'].idxmin()
        best_meta = feasible_df.loc[best_idx].to_dict()

        cols_to_merge = ['wb', 'flyash_frac', 'ggbs_frac', 'composite_score', 'norm_co2', 'norm_cost', 'norm_purpose']
        merge_keys = [k for k in cols_to_merge if k in feasible_df.columns]
        scores_to_merge = feasible_df[merge_keys]
        
        trace_df = trace_df.drop(columns=[k for k in merge_keys if k in trace_df.columns and k not in ['wb', 'flyash_frac', 'ggbs_frac']], errors='ignore')
        trace_df = trace_df.merge(scores_to_merge, on=['wb', 'flyash_frac', 'ggbs_frac'], how='left')

    best_df = best_meta.pop('df', pd.DataFrame())
    return best_df, best_meta, trace_df.to_dict('records')

def generate_baseline(grade, exposure, nom_max, target_slump, agg_shape, 
                      fine_zone, emissions, costs, cement_choice, material_props, 
                      use_sp=True, sp_reduction=0.18,
                      purpose='General', purpose_profile=None):
    
    w_b_limit, min_cem_exp = float(EXPOSURE_WB_LIMITS[exposure]), float(EXPOSURE_MIN_CEMENT[exposure])
    water_target = water_for_slump_and_shape(nom_max_mm=nom_max, slump_mm=int(target_slump), agg_shape=agg_shape, uses_sp=use_sp, sp_reduction_frac=sp_reduction)
    min_b_grade, max_b_grade = reasonable_binder_range(grade)

    binder_for_wb = water_target / w_b_limit
    cementitious = max(binder_for_wb, min_cem_exp, min_b_grade)
    cementitious = min(cementitious, max_b_grade)
    actual_wb = water_target / cementitious
    sp = 0.01 * cementitious if use_sp else 0.0
    coarse_agg_frac = get_coarse_agg_fraction(nom_max, fine_zone, actual_wb)

    density_fa = material_props['sg_fa'] * 1000
    density_ca = material_props['sg_ca'] * 1000
    
    fine_ssd, coarse_ssd = compute_aggregates(cementitious, water_target, sp, coarse_agg_frac, nom_max, density_fa, density_ca)

    water_delta_fa, fine_wet = aggregate_correction(material_props['moisture_fa'], fine_ssd)
    water_delta_ca, coarse_wet = aggregate_correction(material_props['moisture_ca'], coarse_ssd)
    
    water_to_remove = water_delta_fa + water_delta_ca
    water_final = water_target - water_to_remove
    if water_final < 5.0:
        water_final = 5.0

    mix = {cement_choice: cementitious,"Fly Ash": 0.0,"GGBS": 0.0,"Water": water_final, "PCE Superplasticizer": sp,"Fine Aggregate": fine_wet,"Coarse Aggregate": coarse_wet}
    df = evaluate_mix(mix, emissions, costs)
    
    co2_total = float(df["CO2_Emissions (kg/m3)"].sum())
    cost_total = float(df["Cost (₹/m3)"].sum())
    
    meta = {
        "w_b": actual_wb, "cementitious": cementitious, "cement": cementitious, 
        "flyash": 0.0, "ggbs": 0.0, "water_target": water_target, 
        "water_final": water_final, "sp": sp, "fine": fine_wet, 
        "coarse": coarse_wet, "scm_total_frac": 0.0, "grade": grade, 
        "exposure": exposure, "nom_max": nom_max, "slump": target_slump, 
        "co2_total": co2_total,
        "cost_total": cost_total,
        "coarse_agg_fraction": coarse_agg_frac, 
        "material_props": material_props
    }
    
    if purpose_profile is None:
        purpose_profile = PURPOSE_PROFILES.get(purpose, PURPOSE_PROFILES['General'])
        
    purpose_metrics = evaluate_purpose_specific_metrics(meta, purpose)
    purpose_penalty = compute_purpose_penalty(meta, purpose_profile)
    
    meta["purpose"] = purpose
    meta["purpose_metrics"] = purpose_metrics
    meta["purpose_penalty"] = purpose_penalty
    meta["composite_score"] = np.nan
    
    return df, meta

def apply_parser(user_text, current_inputs, use_llm_parser=False):
    if not user_text.strip():
        return current_inputs, [], {}
    try:
        parsed = parse_input_with_llm(user_text) if use_llm_parser else simple_parse(user_text)
    except Exception as e:
        st.warning(f"Parser error: {e}, falling back to regex")
        parsed = simple_parse(user_text)
    messages, updated = [], current_inputs.copy()
    if "grade" in parsed and parsed["grade"] in GRADE_STRENGTH:
        updated["grade"] = parsed["grade"]; messages.append(f"✅ Parser set Grade to **{parsed['grade']}**")
    if "exposure" in parsed and parsed["exposure"] in EXPOSURE_WB_LIMITS:
        updated["exposure"] = parsed["exposure"]; messages.append(f"✅ Parser set Exposure to **{parsed['exposure']}**")
    if "slump" in parsed:
        s = max(25, min(180, int(parsed["slump"])))
        updated["target_slump"] = s; messages.append(f"✅ Parser set Target Slump to **{s} mm**")
    if "cement" in parsed:
        updated["cement_choice"] = parsed["cement"]; messages.append(f"✅ Parser set Cement Type to **{parsed['cement']}**")
    if "nom_max" in parsed and parsed["nom_max"] in [10, 12.5, 20, 40]:
        updated["nom_max"] = parsed["nom_max"]; messages.append(f"✅ Parser set Aggregate Size to **{parsed['nom_max']} mm**")
    return updated, messages, parsed

# ==============================================================================
# PART 3: UI HELPER FUNCTIONS
# ==============================================================================

def _plot_overview_chart(st_col, title, y_label, base_val, opt_val, colors, fmt_str):
    """Helper to create a bar chart for the overview tab."""
    with st_col:
        st.subheader(title)
        chart_data = pd.DataFrame({
            'Mix Type': ['Baseline OPC', 'CivilGPT Optimized'], 
            y_label: [base_val, opt_val]
        })
        fig, ax = plt.subplots(figsize=(6, 4))
        bars = ax.bar(chart_data['Mix Type'], chart_data[y_label], color=colors)
        ax.set_ylabel(y_label)
        ax.bar_label(bars, fmt=fmt_str)
        st.pyplot(fig)

def display_mix_details(title, df, meta, exposure):
    st.header(title)
    
    purpose = meta.get("purpose", "General")
    if purpose != "General":
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("💧 Water/Binder Ratio", f"{meta['w_b']:.3f}")
        c2.metric("📦 Total Binder (kg/m³)", f"{meta['cementitious']:.1f}")
        c3.metric("🎯 Target Strength (MPa)", f"{meta['fck_target']:.1f}")
        c4.metric("⚖️ Unit Weight (kg/m³)", f"{df['Quantity (kg/m3)'].sum():.1f}")
        
        c_p1, c_p2, c_p3 = st.columns(3)
        c_p1.metric("🛠️ Design Purpose", purpose)
        c_p2.metric("⚠️ Purpose Penalty", f"{meta.get('purpose_penalty', 0.0):.2f}", help="Penalty for deviation from purpose targets (lower is better).")
        if "composite_score" in meta and not pd.isna(meta["composite_score"]):
            c_p3.metric("🎯 Composite Score", f"{meta.get('composite_score', 0.0):.3f}", help="Normalized score (lower is better).")
    else:
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("💧 Water/Binder Ratio", f"{meta['w_b']:.3f}")
        c2.metric("📦 Total Binder (kg/m³)", f"{meta['cementitious']:.1f}")
        c3.metric("🎯 Target Strength (MPa)", f"{meta['fck_target']:.1f}")
        c4.metric("⚖️ Unit Weight (kg/m³)", f"{df['Quantity (kg/m3)'].sum():.1f}")

    st.subheader("Mix Proportions (per m³)")
    st.dataframe(df.style.format({
        "Quantity (kg/m3)": "{:.2f}",
        "CO2_Factor(kg_CO2_per_kg)": "{:.3f}",
        "CO2_Emissions (kg/m3)": "{:.2f}",
        "Cost(₹/kg)": "₹{:.2f}",
        "Cost (₹/m3)": "₹{:.2f}"
    }), use_container_width=True)

    st.subheader("Compliance & Sanity Checks (IS 10262 & IS 456)")
    is_feasible, fail_reasons, warnings, derived, checks_dict = check_feasibility(df, meta, exposure)

    if is_feasible:
        st.success("✅ This mix design is compliant with IS code requirements.", icon="👍")
    else:
        st.error(f"❌ This mix fails {len(fail_reasons)} IS code compliance check(s): " + ", ".join(fail_reasons), icon="🚨")

    if warnings:
        for warning in warnings:
            st.warning(warning, icon="⚠️")

    if purpose != "General" and "purpose_metrics" in meta:
        with st.expander(f"Show Estimated Purpose-Specific Metrics ({purpose})"):
            st.json(meta["purpose_metrics"])

    with st.expander("Show detailed calculation parameters"):
        if "purpose_metrics" in derived:
            derived.pop("purpose_metrics", None)
        st.json(derived)

def display_calculation_walkthrough(meta):
    st.header("Step-by-Step Calculation Walkthrough")
    st.markdown(f"""
    This is a summary of how the **Optimized Mix** was designed according to **IS 10262:2019**.

    #### 1. Target Mean Strength
    - **Characteristic Strength (fck):** `{meta['fck']}` MPa (from Grade {meta['grade']})
    - **Assumed Standard Deviation (S):** `{meta['stddev_S']}` MPa (for '{meta.get('qc_level', 'Good')}' quality control)
    - **Target Mean Strength (f'ck):** `fck + 1.65 * S = {meta['fck']} + 1.65 * {meta['stddev_S']} =` **`{meta['fck_target']:.2f}` MPa**

    #### 2. Water Content
    - **Basis:** IS 10262, Table 4, for `{meta['nom_max']}` mm nominal max aggregate size.
    - **Adjustments:** Slump (`{meta['slump']}` mm), aggregate shape ('{meta.get('agg_shape', 'Angular (baseline)')}'), and superplasticizer use.
    - **Final Target Water (SSD basis):** **`{meta['water_target']:.1f}` kg/m³**

    #### 3. Water-Binder (w/b) Ratio
    - **Constraint:** Maximum w/b ratio for `{meta['exposure']}` exposure is `{EXPOSURE_WB_LIMITS[meta['exposure']]}`.
    - **Optimizer Selection:** The optimizer selected the lowest w/b ratio that resulted in a feasible, low-carbon mix.
    - **Selected w/b Ratio:** **`{meta['w_b']:.3f}`**

    #### 4. Binder Content
    - **Initial Binder (from w/b):** `{meta['water_target']:.1f} / {meta['w_b']:.3f} = {(meta['water_target']/meta['w_b']):.1f}` kg/m³
    - **Constraints Check:**
        - Min. for `{meta['exposure']}` exposure: `{EXPOSURE_MIN_CEMENT[meta['exposure']]}` kg/m³
        - Typical range for `{meta['grade']}`: `{meta['binder_range'][0]}` - `{meta['binder_range'][1]}` kg/m³
    - **Final Adjusted Binder Content:** **`{meta['cementitious']:.1f}` kg/m³**

    #### 5. SCM & Cement Content
    - **Optimizer Goal:** Minimize CO₂/cost by replacing cement with SCMs (Fly Ash, GGBS).
    - **Selected SCM Fraction:** `{meta['scm_total_frac']*100:.0f}%`
    - **Material Quantities:**
        - **Cement:** `{meta['cement']:.1f}` kg/m³
        - **Fly Ash:** `{meta['flyash']:.1f}` kg/m³
        - **GGBS:** `{meta['ggbs']:.1f}` kg/m³

    #### 6. Aggregate Proportioning (IS 10262, Table 5)
    - **Basis:** Volume of coarse aggregate for `{meta['nom_max']}` mm aggregate and fine aggregate `{meta.get('fine_zone', 'Zone II')}`.
    - **Adjustment:** Corrected for the final w/b ratio of `{meta['w_b']:.3f}`.
    - **Coarse Aggregate Fraction (by volume):** **`{meta['coarse_agg_fraction']:.3f}`**

    #### 7. Final Quantities (with Moisture Correction)
    - **Fine Aggregate (SSD):** `{(meta['fine'] / (1 + meta['material_props']['moisture_fa']/100)):.1f}` kg/m³
    - **Coarse Aggregate (SSD):** `{(meta['coarse'] / (1 + meta['material_props']['moisture_ca']/100)):.1f}` kg/m³
    - **Moisture Correction:** Adjusted for `{meta['material_props']['moisture_fa']}%` free moisture in fine and `{meta['material_props']['moisture_ca']}%` in coarse aggregate.
    - **Final Batch Weights:**
        - **Water:** **`{meta['water_final']:.1f}` kg/m³**
        - **Fine Aggregate:** **`{meta['fine']:.1f}` kg/m³**
        - **Coarse Aggregate:** **`{meta['coarse']:.1f}` kg/m³**
    """)


# ==============================================================================
# PART 4: STREAMLIT APP (main)
# ==============================================================================

def main():
    st.set_page_config(
        page_title="CivilGPT - Sustainable Concrete Mix Designer",
        page_icon="🧱",
        layout="wide"
    )

    st.markdown("""
    <style>
        .main .block-container {
            padding-top: 2rem; padding-bottom: 2rem;
            padding-left: 5rem; padding-right: 5rem;
        }
        .st-emotion-cache-1y4p8pa { max-width: 100%; }
        .stTextArea [data-baseweb=base-input] {
            border-color: #4A90E2; box-shadow: 0 0 5px #4A90E2;
        }
    </style>
    """, unsafe_allow_html=True)

    st.title("🧱 CivilGPT: Sustainable Concrete Mix Designer")
    st.markdown("##### An AI-powered tool for creating **IS 10262:2019 compliant** concrete mixes, optimized for low carbon footprint.")

    col1, col2 = st.columns([0.7, 0.3])
    with col1:
        user_text = st.text_area(
            "**Describe Your Requirements**",
            height=100,
            placeholder="e.g., Design an M30 grade concrete for severe exposure using OPC 43. Target a slump of 125 mm with 20 mm aggregates.",
            label_visibility="collapsed",
            key="user_text_input"
        )
    with col2:
        st.write("")
        st.write("")
        run_button = st.button("🚀 Generate Mix Design", use_container_width=True, type="primary")

    manual_mode = st.toggle("⚙️ Switch to Advanced Manual Input")
    purpose_profiles_data = load_purpose_profiles()

    if 'user_text_input' not in st.session_state:
        st.session_state.user_text_input = ""

    if manual_mode:
        st.sidebar.header("📝 Manual Mix Inputs")
        st.sidebar.markdown("---")
        st.sidebar.subheader("Core Requirements")
        grade = st.sidebar.selectbox("Concrete Grade", list(GRADE_STRENGTH.keys()), index=4, help="Target characteristic compressive strength at 28 days.")
        exposure = st.sidebar.selectbox("Exposure Condition", list(EXPOSURE_WB_LIMITS.keys()), index=2, help="Determines durability requirements like min. cement content and max. water-binder ratio as per IS 456.")
        st.sidebar.subheader("Workability & Materials")
        target_slump = st.sidebar.slider("Target Slump (mm)", 25, 180, 100, 5, help="Specifies the desired consistency and workability of the fresh concrete.")
        cement_choice = st.sidebar.selectbox("Cement Type", ["OPC 43"], index=0, help="Type of Ordinary Portland Cement.")
        nom_max = st.sidebar.selectbox("Nominal Max. Aggregate Size (mm)", [10, 12.5, 20, 40], index=2, help="Largest practical aggregate size, influences water demand.")
        agg_shape = st.sidebar.selectbox("Coarse Aggregate Shape", list(AGG_SHAPE_WATER_ADJ.keys()), index=0, help="Shape affects water demand; angular requires more water than rounded.")
        fine_zone = st.sidebar.selectbox("Fine Aggregate Zone (IS 383)", ["Zone I","Zone II","Zone III","Zone IV"], index=1, help="Grading zone as per IS 383. This is crucial for determining aggregate proportions per IS 10262.")
        use_sp = st.sidebar.checkbox("Use Superplasticizer (PCE)", True, help="Chemical admixture to increase workability or reduce water content.")
        
        st.sidebar.subheader("Optimization Goal")
        purpose = st.sidebar.selectbox(
            "Design Purpose", 
            list(purpose_profiles_data.keys()), 
            index=0, 
            key="purpose_select",
            help=purpose_profiles_data.get(st.session_state.get("purpose_select", "General"), {}).get("description", "Select the structural element.")
        )
        optimize_for = st.sidebar.selectbox(
            "Optimization Objective",
            ["CO₂ Emissions", "Cost"],
            index=0,
            help="Choose whether to optimize the mix for cost or CO₂ footprint.",
            key="optimize_for_select"
        )
        optimize_cost = (optimize_for == "Cost")
        enable_purpose_optimization = st.sidebar.checkbox(
            "Enable Purpose-Based Composite Optimization", 
            value=(purpose != 'General'), 
            key="enable_purpose",
            help="Optimize for a composite score balancing CO₂, Cost, and Purpose-Fit. If unchecked, uses the 'Single-Objective Priority' above."
        )

        if enable_purpose_optimization and purpose != 'General':
            with st.sidebar.expander("Adjust Optimization Weights", expanded=True):
                default_weights = purpose_profiles_data.get(purpose, {}).get('weights', purpose_profiles_data['General']['weights'])
                w_co2 = st.slider("🌱 CO₂ Weight", 0.0, 1.0, default_weights['co2'], 0.05, key="w_co2")
                w_cost = st.slider("💰 Cost Weight", 0.0, 1.0, default_weights['cost'], 0.05, key="w_cost")
                w_purpose = st.slider("🛠️ Purpose-Fit Weight", 0.0, 1.0, default_weights['purpose'], 0.05, key="w_purpose")
                
                total_w = w_co2 + w_cost + w_purpose
                if total_w == 0:
                    st.warning("Weights cannot all be zero. Defaulting to balanced weights.")
                    purpose_weights = {"w_co2": 0.33, "w_cost": 0.33, "w_purpose": 0.34}
                else:
                    purpose_weights = {"w_co2": w_co2 / total_w, "w_cost": w_cost / total_w, "w_purpose": w_purpose / total_w}
                    st.caption(f"Normalized: CO₂ {purpose_weights['w_co2']:.1%}, Cost {purpose_weights['w_cost']:.1%}, Purpose {purpose_weights['w_purpose']:.1%}")
        else:
            purpose_weights = purpose_profiles_data['General']['weights']
            if enable_purpose_optimization and purpose == 'General':
                st.sidebar.info("Purpose 'General' uses single-objective optimization (CO₂ or Cost).")
                enable_purpose_optimization = False

        st.sidebar.subheader("Advanced Parameters")
        with st.sidebar.expander("QA/QC"):
            qc_level = st.selectbox("Quality Control Level", list(QC_STDDEV.keys()), index=0, help="Assumed site quality control, affecting the target strength calculation (f_target = fck + 1.65 * S).")

        with st.sidebar.expander("Material Properties (from Library or Manual)"):
            materials_file = st.file_uploader("Upload Materials Library CSV", type=["csv"], key="materials_csv", help="CSV with 'Material', 'SpecificGravity', 'MoistureContent', 'WaterAbsorption' columns.")
            sg_fa_default, moisture_fa_default = 2.65, 1.0
            sg_ca_default, moisture_ca_default = 2.70, 0.5

            if materials_file is not None:
                try:
                    materials_file.seek(0)
                    temp_mat_df = pd.read_csv(materials_file)
                    mat_df = _normalize_columns(temp_mat_df, MATERIALS_COL_MAP)
                    mat_df['Material'] = mat_df['Material'].str.strip().lower()
                    fa_row = mat_df[mat_df['Material'] == 'fine aggregate']
                    if not fa_row.empty:
                        if 'SpecificGravity' in fa_row: sg_fa_default = float(fa_row['SpecificGravity'].iloc[0])
                        if 'MoistureContent' in fa_row: moisture_fa_default = float(fa_row['MoistureContent'].iloc[0])
                    ca_row = mat_df[mat_df['Material'] == 'coarse aggregate']
                    if not ca_row.empty:
                        if 'SpecificGravity' in ca_row: sg_ca_default = float(ca_row['SpecificGravity'].iloc[0])
                        if 'MoistureContent' in ca_row: moisture_ca_default = float(ca_row['MoistureContent'].iloc[0])
                    st.success("Materials library CSV loaded and properties updated.")
                except Exception as e:
                    st.error(f"Failed to parse materials CSV: {e}")

            st.markdown("###### Fine Aggregate")
            sg_fa = st.number_input("Specific Gravity (FA)", 2.0, 3.0, sg_fa_default, 0.01)
            moisture_fa = st.number_input("Free Moisture Content % (FA)", -2.0, 5.0, moisture_fa_default, 0.1, help="Moisture beyond SSD condition. Negative if absorbent.")
            st.markdown("###### Coarse Aggregate")
            sg_ca = st.number_input("Specific Gravity (CA)", 2.0, 3.0, sg_ca_default, 0.01)
            moisture_ca = st.number_input("Free Moisture Content % (CA)", -2.0, 5.0, moisture_ca_default, 0.1, help="Moisture beyond SSD condition. Negative if absorbent.")

        st.sidebar.subheader("File Uploads (Optional)")
        with st.sidebar.expander("Upload Sieve Analysis & Financials"):
            st.markdown("###### Sieve Analysis (IS 383)")
            fine_csv = st.file_uploader("Fine Aggregate CSV", type=["csv"], key="fine_csv", help="CSV with 'Sieve_mm' and 'PercentPassing' columns.")
            coarse_csv = st.file_uploader("Coarse Aggregate CSV", type=["csv"], key="coarse_csv", help="CSV with 'Sieve_mm' and 'PercentPassing' columns.")
            st.markdown("###### Cost & Emissions Data")
            emissions_file = st.file_uploader("Emission Factors (kgCO₂/kg)", type=["csv"], key="emissions_csv")
            cost_file = st.file_uploader("Cost Factors (₹/kg)", type=["csv"], key="cost_csv")

        with st.sidebar.expander("🔬 Lab Calibration Dataset"):
            st.markdown("""
            Upload a CSV with lab results to compare against CivilGPT's predictions.
            **Required columns:**
            - `grade` (e.g., M30)
            - `exposure` (e.g., Severe)
            - `slump` (mm)
            - `nom_max` (mm)
            - `cement_choice` (e.g., OPC 43)
            - `actual_strength` (MPa)
            """)
            lab_csv = st.file_uploader("Upload Lab Data CSV", type=["csv"], key="lab_csv")

        st.sidebar.markdown("---")
        use_llm_parser = st.sidebar.checkbox("Use Groq LLM Parser", value=False, help="Use a Large Language Model for parsing the text prompt. Requires API key.")

    else: # Default values when manual mode is off
        grade, exposure, cement_choice = "M30", "Severe", "OPC 43"
        nom_max, agg_shape, target_slump = 20, "Angular (baseline)", 125
        use_sp, optimize_cost, fine_zone = True, False, "Zone II"
        optimize_for = "CO₂ Emissions"
        qc_level = "Good"
        sg_fa, moisture_fa = 2.65, 1.0
        sg_ca, moisture_ca = 2.70, 0.5
        fine_csv, coarse_csv, lab_csv = None, None, None
        emissions_file, cost_file, materials_file = None, None, None
        use_llm_parser = False
        purpose = "General"
        enable_purpose_optimization = False
        purpose_weights = purpose_profiles_data['General']['weights']

    with st.sidebar.expander("Calibration & Tuning (Developer)"):
        enable_calibration_overrides = st.checkbox("Enable calibration overrides", False, help="Override default optimizer search parameters with the values below.")
        calib_wb_min = st.number_input("W/B search minimum (wb_min)", 0.30, 0.45, 0.35, 0.01, help="Lower bound for the Water/Binder ratio search space.")
        calib_wb_steps = st.slider("W/B search steps (wb_steps)", 3, 15, 6, 1, help="Number of W/B ratios to test between min and the exposure limit.")
        calib_fine_fraction = st.slider("Fine Aggregate Fraction (fine_fraction)", 0.30, 0.50, 0.40, 0.01, help="Manually overrides the IS 10262 calculation for aggregate proportions.")
        calib_max_flyash_frac = st.slider("Max Fly Ash fraction", 0.0, 0.5, 0.30, 0.05, help="Maximum Fly Ash replacement percentage to test.")
        calib_max_ggbs_frac = st.slider("Max GGBS fraction", 0.0, 0.5, 0.50, 0.05, help="Maximum GGBS replacement percentage to test.")
        calib_scm_step = st.slider("SCM fraction step (scm_step)", 0.05, 0.25, 0.10, 0.05, help="Step size for testing different SCM replacement percentages.")

    materials_df, emissions_df, costs_df = load_data(materials_file, emissions_file, cost_file)

    # --- Main Execution Block ---
    if 'clarification_needed' not in st.session_state:
        st.session_state.clarification_needed = False
    if 'run_generation' not in st.session_state:
        st.session_state.run_generation = False
    if 'final_inputs' not in st.session_state:
        st.session_state.final_inputs = {}

    CLARIFICATION_WIDGETS = {
        "grade": lambda v: st.selectbox("Concrete Grade", list(GRADE_STRENGTH.keys()), index=list(GRADE_STRENGTH.keys()).index(v) if v in GRADE_STRENGTH else 4),
        "exposure": lambda v: st.selectbox("Exposure Condition", list(EXPOSURE_WB_LIMITS.keys()), index=list(EXPOSURE_WB_LIMITS.keys()).index(v) if v in EXPOSURE_WB_LIMITS else 2),
        "target_slump": lambda v: st.slider("Target Slump (mm)", 25, 180, v if isinstance(v, int) else 100, 5),
        "cement_choice": lambda v: st.selectbox("Cement Type", ["OPC 43"], index=0),
        "nom_max": lambda v: st.selectbox("Nominal Max. Aggregate Size (mm)", [10, 12.5, 20, 40], index=[10, 12.5, 20, 40].index(v) if v in [10, 12.5, 20, 40] else 2),
    }

    if run_button:
        st.session_state.run_generation = True
        st.session_state.clarification_needed = False
        if 'results' in st.session_state:
            del st.session_state.results

        material_props = {'sg_fa': sg_fa, 'moisture_fa': moisture_fa, 'sg_ca': sg_ca, 'moisture_ca': moisture_ca}
        inputs = { 
            "grade": grade, "exposure": exposure, "cement_choice": cement_choice, 
            "nom_max": nom_max, "agg_shape": agg_shape, "target_slump": target_slump, 
            "use_sp": use_sp, "optimize_cost": optimize_cost, "qc_level": qc_level, 
            "fine_zone": fine_zone, "material_props": material_props,
            "purpose": purpose, 
            "enable_purpose_optimization": enable_purpose_optimization, 
            "purpose_weights": purpose_weights,
            "optimize_for": optimize_for
        }

        if user_text.strip() and not manual_mode:
            with st.spinner("🤖 Parsing your request..."):
                inputs, msgs, _ = apply_parser(user_text, inputs, use_llm_parser=use_llm_parser)
            if msgs:
                st.info(" ".join(msgs), icon="💡")
            
            required_fields = ["grade", "exposure", "target_slump", "nom_max", "cement_choice"]
            missing_fields = [f for f in required_fields if inputs.get(f) is None]

            if missing_fields:
                st.session_state.clarification_needed = True
                st.session_state.final_inputs = inputs
                st.session_state.missing_fields = missing_fields
                st.session_state.run_generation = False
            else:
                st.session_state.run_generation = True
                st.session_state.final_inputs = inputs
        else:
            st.session_state.run_generation = True
            st.session_state.final_inputs = inputs

    if st.session_state.get('clarification_needed', False):
        st.markdown("---")
        st.warning("Your request is missing some details. Please confirm the following to continue.", icon="🤔")
        st.markdown("Please confirm the missing values below. Once submitted, mix design will start automatically.")
        with st.form("clarification_form"):
            st.subheader("Please Clarify Your Requirements")
            current_inputs = st.session_state.final_inputs
            missing_fields_list = st.session_state.missing_fields

            num_cols = min(len(missing_fields_list), 3)
            cols = st.columns(num_cols)
            for i, field in enumerate(missing_fields_list):
                with cols[i % num_cols]:
                    widget_func = CLARIFICATION_WIDGETS[field]
                    current_value = current_inputs.get(field)
                    new_value = widget_func(current_value)
                    current_inputs[field] = new_value

            submitted = st.form_submit_button("✅ Confirm & Continue", use_container_width=True, type="primary")

            if submitted:
                st.session_state.final_inputs = current_inputs
                st.session_state.clarification_needed = False
                st.session_state.run_generation = True
                if 'results' in st.session_state:
                    del st.session_state.results
                st.rerun()

    # ==============================================================================
    # COMPUTATION BLOCK
    # ==============================================================================
    if st.session_state.get('run_generation', False):
        st.markdown("---")
        try:
            inputs = st.session_state.final_inputs

            min_grade_req = EXPOSURE_MIN_GRADE[inputs["exposure"]]
            grade_order = list(GRADE_STRENGTH.keys())
            if grade_order.index(inputs["grade"]) < grade_order.index(min_grade_req):
                st.warning(f"For **{inputs['exposure']}** exposure, IS 456 recommends a minimum grade of **{min_grade_req}**. The grade has been automatically updated.", icon="⚠️")
                inputs["grade"] = min_grade_req
                st.session_state.final_inputs["grade"] = min_grade_req

            calibration_kwargs = {}
            if enable_calibration_overrides:
                calibration_kwargs = {
                    "wb_min": calib_wb_min,
                    "wb_steps": calib_wb_steps,
                    "max_flyash_frac": calib_max_flyash_frac,
                    "max_ggbs_frac": calib_max_ggbs_frac,
                    "scm_step": calib_scm_step,
                    "fine_fraction_override": calib_fine_fraction
                }
                st.info("Developer calibration overrides are enabled.", icon="🛠️")

            purpose = inputs.get('purpose', 'General')
            purpose_profile = purpose_profiles_data.get(purpose, purpose_profiles_data['General'])
            enable_purpose_opt = inputs.get('enable_purpose_optimization', False)
            purpose_weights = inputs.get('purpose_weights', purpose_profiles_data['General']['weights'])
            
            if purpose == 'General':
                enable_purpose_opt = False
            
            if enable_purpose_opt:
                st.info(f"🚀 Running composite optimization for **{purpose}**.", icon="🛠️")
            else:
                st.info(f"Running single-objective optimization for **{inputs.get('optimize_for', 'CO₂ Emissions')}**.", icon="⚙️")
            
            with st.spinner("⚙️ Running IS-code calculations and optimizing..."):
                fck, S = GRADE_STRENGTH[inputs["grade"]], QC_STDDEV[inputs.get("qc_level", "Good")]
                fck_target = fck + 1.65 * S
                
                opt_df, opt_meta, trace = generate_mix(
                    inputs["grade"], inputs["exposure"], inputs["nom_max"],
                    inputs["target_slump"], inputs["agg_shape"], inputs["fine_zone"],
                    emissions_df, costs_df, inputs["cement_choice"],
                    material_props=inputs["material_props"],
                    use_sp=inputs["use_sp"], 
                    optimize_cost=inputs["optimize_cost"],
                    purpose=purpose,
                    purpose_profile=purpose_profile,
                    purpose_weights=purpose_weights,
                    enable_purpose_optimization=enable_purpose_opt,
                    **calibration_kwargs
                )
                
                base_df, base_meta = generate_baseline(
                    inputs["grade"], inputs["exposure"], inputs["nom_max"],
                    inputs["target_slump"], inputs["agg_shape"], inputs["fine_zone"],
                    emissions_df, costs_df, inputs["cement_choice"],
                    material_props=inputs["material_props"],
                    use_sp=inputs["use_sp"],
                    purpose=purpose,
                    purpose_profile=purpose_profile
                )

            if opt_df is None or base_df is None:
                st.error("Could not find a feasible mix design with the given constraints. Try adjusting the parameters, such as a higher grade or less restrictive exposure condition.", icon="❌")
                st.dataframe(pd.DataFrame(trace))
                st.session_state.results = {"success": False, "trace": trace}
            else:
                st.success(f"Successfully generated mix designs for **{inputs['grade']}** concrete in **{inputs['exposure']}** conditions.", icon="✅")
                for m in (opt_meta, base_meta):
                    m["fck"], m["fck_target"], m["stddev_S"] = fck, round(fck_target, 1), S
                    m["qc_level"] = inputs.get("qc_level", "Good")
                    m["agg_shape"] = inputs.get("agg_shape")
                    m["fine_zone"] = inputs.get("fine_zone")
                
                st.session_state.results = {
                    "success": True,
                    "opt_df": opt_df, "opt_meta": opt_meta,
                    "base_df": base_df, "base_meta": base_meta,
                    "trace": trace, "inputs": inputs,
                    "fck_target": fck_target, "fck": fck, "S": S
                }

        except Exception as e:
            st.error(f"An unexpected error occurred: {e}", icon="💥")
            st.code(traceback.format_exc())
            st.session_state.results = {"success": False, "trace": None}
        finally:
            st.session_state.run_generation = False

    # ==============================================================================
    # DISPLAY BLOCK
    # ==============================================================================
    if 'results' in st.session_state and st.session_state.results["success"]:
        
        results = st.session_state.results
        opt_df, opt_meta = results["opt_df"], results["opt_meta"]
        base_df, base_meta = results["base_df"], results["base_meta"]
        trace, inputs = results["trace"], results["inputs"]
        
        tab1, tab2, tab3, tab_pareto, tab4, tab5, tab6 = st.tabs([
            "📊 **Overview**",
            "🌱 **Optimized Mix**",
            "🏗️ **Baseline Mix**",
            "⚖️ **Trade-off Explorer**",
            "📋 **QA/QC & Gradation**",
            "📥 **Downloads & Reports**",
            "🔬 **Lab Calibration**"
        ])

        with tab1:
            co2_opt, cost_opt = opt_meta["co2_total"], opt_meta["cost_total"]
            co2_base, cost_base = base_meta["co2_total"], base_meta["cost_total"]
            reduction = (co2_base - co2_opt) / co2_base * 100 if co2_base > 0 else 0.0
            cost_savings = cost_base - cost_opt

            st.subheader("Performance At a Glance")
            c1, c2, c3 = st.columns(3)
            c1.metric("🌱 CO₂ Reduction", f"{reduction:.1f}%", f"{co2_base - co2_opt:.1f} kg/m³ saved")
            c2.metric("💰 Cost Savings", f"₹{cost_savings:,.0f} / m³", f"{cost_savings/cost_base*100 if cost_base>0 else 0:.1f}% cheaper")
            c3.metric("♻️ SCM Content", f"{opt_meta['scm_total_frac']*100:.0f}%", f"{base_meta['scm_total_frac']*100:.0f}% in baseline", help="Supplementary Cementitious Materials (Fly Ash, GGBS) replace high-carbon cement.")
            
            if opt_meta.get("purpose", "General") != "General":
                st.markdown("---")
                c_p1, c_p2, c_p3 = st.columns(3)
                c_p1.metric("🛠️ Design Purpose", opt_meta['purpose'])
                c_p2.metric("🎯 Composite Score", f"{opt_meta.get('composite_score', 0.0):.3f}", help="Normalized score (lower is better) balancing CO₂, Cost, and Purpose-Fit.")
                c_p3.metric("⚠️ Purpose Penalty", f"{opt_meta.get('purpose_penalty', 0.0):.2f}", help="Penalty for deviation from purpose targets (lower is better).")

            st.markdown("---")
            col1, col2 = st.columns(2)
            _plot_overview_chart(col1, "📊 Embodied Carbon (CO₂e)", "CO₂ (kg/m³)", 
                                co2_base, co2_opt, ['#D3D3D3', '#4CAF50'], '{:,.1f}')
            _plot_overview_chart(col2, "💵 Material Cost", "Cost (₹/m³)", 
                                cost_base, cost_opt, ['#D3D3D3', '#2196F3'], '₹{:,.0f}')

        with tab2:
            display_mix_details("🌱 Optimized Low-Carbon Mix Design", opt_df, opt_meta, inputs['exposure'])
            if st.toggle("📖 Show Step-by-Step IS Calculation", key="toggle_walkthrough_tab2"):
                display_calculation_walkthrough(opt_meta)

        with tab3:
            display_mix_details("🏗️ Standard OPC Baseline Mix Design", base_df, base_meta, inputs['exposure'])

        with tab_pareto:
            st.header("Cost vs. Carbon Trade-off Analysis")
            st.markdown("This chart displays all IS-code compliant mixes found by the optimizer. The blue line represents the **Pareto Front**—the set of most efficient mixes where you can't improve one objective (e.g., lower CO₂) without worsening the other (e.g., increasing cost).")

            if trace:
                trace_df = pd.DataFrame(trace)
                feasible_mixes = trace_df[trace_df['feasible']].copy()

                if not feasible_mixes.empty:
                    pareto_df = pareto_front(feasible_mixes, x_col="cost", y_col="co2")

                    if not pareto_df.empty:
                        alpha = st.slider(
                            "Prioritize Sustainability (CO₂) ↔ Cost",
                            min_value=0.0, max_value=1.0, value=st.session_state.get("pareto_slider_alpha", 0.5), step=0.05,
                            help="Slide towards Sustainability to prioritize low CO₂, or towards Cost to prioritize low price. The green diamond will show the best compromise on the Pareto Front for your chosen preference.",
                            key="pareto_slider_alpha"
                        )

                        pareto_df_norm = pareto_df.copy()
                        cost_min, cost_max = pareto_df_norm['cost'].min(), pareto_df_norm['cost'].max()
                        co2_min, co2_max = pareto_df_norm['co2'].min(), pareto_df_norm['co2'].max()

                        pareto_df_norm['norm_cost'] = 0.0 if (cost_max - cost_min) == 0 else (pareto_df_norm['cost'] - cost_min) / (cost_max - cost_min)
                        pareto_df_norm['norm_co2'] = 0.0 if (co2_max - co2_min) == 0 else (pareto_df_norm['co2'] - co2_min) / (co2_max - co2_min)
                        pareto_df_norm['score'] = alpha * pareto_df_norm['norm_co2'] + (1 - alpha) * pareto_df_norm['norm_cost']

                        best_compromise_mix = pareto_df_norm.loc[pareto_df_norm['score'].idxmin()]

                        fig, ax = plt.subplots(figsize=(10, 6))
                        ax.scatter(feasible_mixes["cost"], feasible_mixes["co2"], color='grey', alpha=0.5, label='All Feasible Mixes', zorder=1)
                        
                        pareto_df_sorted = pareto_df.sort_values(by="cost")
                        ax.plot(pareto_df_sorted["cost"], pareto_df_sorted["co2"], '-o', color='blue', label='Pareto Front (Efficient Mixes)', linewidth=2, zorder=2)
                        
                        if inputs.get('enable_purpose_optimization', False) and inputs.get('purpose', 'General') != 'General':
                            optimize_for_label = f"Composite Score ({inputs['purpose']})"
                        else:
                            optimize_for_label = inputs.get('optimize_for', 'CO₂ Emissions')
                        
                        ax.plot(opt_meta['cost_total'], opt_meta['co2_total'], '*', markersize=15, color='red', label=f'Chosen Mix ({optimize_for_label})', zorder=3)
                        ax.plot(best_compromise_mix['cost'], best_compromise_mix['co2'], 'D', markersize=10, color='green', label='Best Compromise (from slider)', zorder=3)

                        ax.set_xlabel("Material Cost (₹/m³)")
                        ax.set_ylabel("Embodied Carbon (kg CO₂e / m³)")
                        ax.set_title("Pareto Front of Feasible Concrete Mixes")
                        ax.grid(True, linestyle='--', alpha=0.6)
                        ax.legend()
                        st.pyplot(fig)

                        st.markdown("---")
                        st.subheader("Details of Selected 'Best Compromise' Mix")
                        c1, c2, c3 = st.columns(3)
                        c1.metric("💰 Cost", f"₹{best_compromise_mix['cost']:.0f} / m³")
                        c2.metric("🌱 CO₂", f"{best_compromise_mix['co2']:.1f} kg / m³")
                        c3.metric("💧 Water/Binder Ratio", f"{best_compromise_mix['wb']:.3f}")
                        
                        if 'composite_score' in best_compromise_mix and not pd.isna(best_compromise_mix['composite_score']):
                            c4, c5 = st.columns(2)
                            c4.metric("⚠️ Purpose Penalty", f"{best_compromise_mix['purpose_penalty']:.2f}")
                            c5.metric("🎯 Composite Score", f"{best_compromise_mix['composite_score']:.3f}")
                    else:
                        st.info("No Pareto front could be determined from the feasible mixes.", icon="ℹ️")
                else:
                    st.warning("No feasible mixes were found by the optimizer, so no trade-off plot can be generated.", icon="⚠️")
            else:
                st.error("Optimizer trace data is missing.", icon="❌")

        with tab4:
            st.header("Quality Assurance & Sieve Analysis")

            sample_fa_data = "Sieve_mm,PercentPassing\n4.75,95\n2.36,80\n1.18,60\n0.600,40\n0.300,15\n0.150,5"
            sample_ca_data = "Sieve_mm,PercentPassing\n40.0,100\n20.0,98\n10.0,40\n4.75,5"

            col1, col2 = st.columns(2)
            with col1:
                st.subheader("Fine Aggregate Gradation")
                if fine_csv is not None:
                    try:
                        fine_csv.seek(0)
                        df_fine = pd.read_csv(fine_csv)
                        ok_fa, msgs_fa = sieve_check_fa(df_fine, inputs.get("fine_zone", "Zone II"))
                        if ok_fa: st.success(msgs_fa[0], icon="✅")
                        else:
                            for m in msgs_fa: st.error(m, icon="❌")
                        st.dataframe(df_fine, use_container_width=True)
                    except Exception as e:
                        st.error(f"Error processing Fine Aggregate CSV: {e}")
                else:
                    st.info("Upload a Fine Aggregate CSV in the sidebar to perform a gradation check against IS 383.", icon="ℹ️")
                    st.download_button(
                        label="Download Sample Fine Agg. CSV",
                        data=sample_fa_data,
                        file_name="sample_fine_aggregate.csv",
                        mime="text/csv",
                    )
            with col2:
                st.subheader("Coarse Aggregate Gradation")
                if coarse_csv is not None:
                    try:
                        coarse_csv.seek(0)
                        df_coarse = pd.read_csv(coarse_csv)
                        ok_ca, msgs_ca = sieve_check_ca(df_coarse, inputs["nom_max"])
                        if ok_ca: st.success(msgs_ca[0], icon="✅")
                        else:
                            for m in msgs_ca: st.error(m, icon="❌")
                        st.dataframe(df_coarse, use_container_width=True)
                    except Exception as e:
                        st.error(f"Error processing Coarse Aggregate CSV: {e}")
                else:
                    st.info("Upload a Coarse Aggregate CSV in the sidebar to perform a gradation check against IS 383.", icon="ℹ️")
                    st.download_button(
                        label="Download Sample Coarse Agg. CSV",
                        data=sample_ca_data,
                        file_name="sample_coarse_aggregate.csv",
                        mime="text/csv",
                    )

            st.markdown("---")
            with st.expander("📖 View Step-by-Step Calculation Walkthrough"):
                display_calculation_walkthrough(opt_meta)

            with st.expander("🔬 View Optimizer Trace (Advanced)"):
                if trace:
                    trace_df = pd.DataFrame(trace)
                    st.markdown("The table below shows every mix combination attempted by the optimizer. 'Feasible' mixes met all IS-code checks.")
                    
                    def style_feasible_cell(v):
                        return 'background-color: #e8f5e9; color: #155724; text-align: center;' if v else 'background-color: #ffebee; color: #721c24; text-align: center;'
                    
                    st.dataframe(
                        trace_df.style
                            .apply(lambda s: [style_feasible_cell(v) for v in s], subset=['feasible'])
                            .format({
                                "feasible": lambda v: "✅" if v else "❌",
                                "wb": "{:.3f}", "flyash_frac": "{:.2f}", "ggbs_frac": "{:.2f}",
                                "co2": "{:.1f}", "cost": "{:.1f}",
                                "purpose_penalty": "{:.2f}", "composite_score": "{:.4f}",
                                "norm_co2": "{:.3f}", "norm_cost": "{:.3f}", "norm_purpose": "{:.3f}",
                            }),
                        use_container_width=True
                    )
                    
                    st.markdown("#### CO₂ vs. Cost of All Candidate Mixes")
                    fig, ax = plt.subplots()
                    scatter_colors = ["#4CAF50" if f else "#F44336" for f in trace_df["feasible"]]
                    ax.scatter(trace_df["cost"], trace_df["co2"], c=scatter_colors, alpha=0.6)
                    ax.set_xlabel("Material Cost (₹/m³)")
                    ax.set_ylabel("Embodied Carbon (kg CO₂e/m³)")
                    ax.grid(True, linestyle='--', alpha=0.6)
                    st.pyplot(fig)
                else:
                    st.info("Trace not available.")

        with tab5:
            st.header("Download Reports")

            excel_buffer = BytesIO()
            with pd.ExcelWriter(excel_buffer, engine="xlsxwriter") as writer:
                opt_df.to_excel(writer, sheet_name="Optimized_Mix", index=False)
                base_df.to_excel(writer, sheet_name="Baseline_Mix", index=False)
                pd.DataFrame([opt_meta]).T.to_excel(writer, sheet_name="Optimized_Meta")
                pd.DataFrame([base_meta]).T.to_excel(writer, sheet_name="Baseline_Meta")
                if trace:
                    pd.DataFrame(trace).to_excel(writer, sheet_name="Optimizer_Trace", index=False)
            excel_buffer.seek(0)

            pdf_buffer = BytesIO()
            doc = SimpleDocTemplate(pdf_buffer, pagesize=(8.5*inch, 11*inch))
            styles = getSampleStyleSheet()
            story = [Paragraph("CivilGPT Sustainable Mix Report", styles['h1']), Spacer(1, 0.2*inch)]

            summary_data = [
                ["Metric", "Optimized Mix", "Baseline Mix"],
                ["CO₂ (kg/m³)", f"{opt_meta['co2_total']:.1f}", f"{base_meta['co2_total']:.1f}"],
                ["Cost (₹/m³)", f"₹{opt_meta['cost_total']:,.2f}", f"₹{base_meta['cost_total']:,.2f}"],
                ["w/b Ratio", f"{opt_meta['w_b']:.3f}", f"{base_meta['w_b']:.3f}"],
                ["Binder (kg/m³)", f"{opt_meta['cementitious']:.1f}", f"{base_meta['cementitious']:.1f}"],
                ["Purpose", f"{opt_meta.get('purpose', 'N/A')}", f"{base_meta.get('purpose', 'N/A')}"],
                ["Composite Score", f"{opt_meta.get('composite_score', 'N/A'):.3f}" if 'composite_score' in opt_meta and not pd.isna(opt_meta['composite_score']) else "N/A", "N/A"],
            ]
            summary_table = Table(summary_data, hAlign='LEFT', colWidths=[2*inch, 1.5*inch, 1.5*inch])
            summary_table.setStyle(TableStyle([('GRID', (0,0), (-1,-1), 1, colors.black), ('BACKGROUND', (0,0), (-1,0), colors.lightgrey)]))
            story.extend([Paragraph(f"Design for <b>{inputs['grade']} / {inputs['exposure']} Exposure</b>", styles['h2']), summary_table, Spacer(1, 0.2*inch)])

            opt_data_pdf = [opt_df.columns.values.tolist()] + opt_df.applymap(lambda x: f'{x:.2f}' if isinstance(x, float) else x).values.tolist()
            opt_table = Table(opt_data_pdf, hAlign='LEFT')
            opt_table.setStyle(TableStyle([('GRID', (0,0), (-1,-1), 1, colors.black), ('BACKGROUND', (0,0), (-1,0), colors.palegreen)]))
            story.extend([Paragraph("Optimized Mix Proportions (kg/m³)", styles['h2']), opt_table])
            doc.build(story)
            pdf_buffer.seek(0)

            d1, d2 = st.columns(2)
            with d1:
                st.download_button("📄 Download PDF Report", data=pdf_buffer.getvalue(), file_name="CivilGPT_Report.pdf", mime="application/pdf", use_container_width=True)
                st.download_button("📈 Download Excel Report", data=excel_buffer.getvalue(), file_name="CivilGPT_Mix_Designs.xlsx", mime="application/vnd.ms-excel", use_container_width=True)
            with d2:
                st.download_button("✔️ Optimized Mix (CSV)", data=opt_df.to_csv(index=False).encode("utf-8"), file_name="optimized_mix.csv", mime="text/csv", use_container_width=True)
                st.download_button("✖️ Baseline Mix (CSV)", data=base_df.to_csv(index=False).encode("utf-8"), file_name="baseline_mix.csv", mime="text/csv", use_container_width=True)

        with tab6:
            st.header("🔬 Lab Calibration Analysis")
            if lab_csv is not None:
                try:
                    lab_csv.seek(0)
                    lab_results_df = pd.read_csv(lab_csv)
                    comparison_df, error_metrics = run_lab_calibration(lab_results_df)

                    if comparison_df is not None and not comparison_df.empty:
                        st.subheader("Error Metrics")
                        st.markdown("Comparing lab-tested 28-day strength against the IS code's required target strength (`f_target = fck + 1.65 * S`).")
                        m1, m2, m3 = st.columns(3)
                        m1.metric(label="Mean Absolute Error (MAE)", value=f"{error_metrics['Mean Absolute Error (MPa)']:.2f} MPa")
                        m2.metric(label="Root Mean Squared Error (RMSE)", value=f"{error_metrics['Root Mean Squared Error (MPa)']:.2f} MPa")
                        m3.metric(label="Mean Bias (Over/Under-prediction)", value=f"{error_metrics['Mean Bias (MPa)']:.2f} MPa")
                        st.markdown("---")

                        st.subheader("Comparison: Lab vs. Predicted Target Strength")
                        st.dataframe(comparison_df.style.format({
                            "Lab Strength (MPa)": "{:.2f}",
                            "Predicted Target Strength (MPa)": "{:.2f}",
                            "Error (MPa)": "{:+.2f}"
                        }), use_container_width=True)

                        st.subheader("Prediction Accuracy Scatter Plot")
                        fig, ax = plt.subplots()
                        ax.scatter(comparison_df["Lab Strength (MPa)"], comparison_df["Predicted Target Strength (MPa)"], alpha=0.7, label="Data Points")
                        lims = [
                            np.min([ax.get_xlim(), ax.get_ylim()]),
                            np.max([ax.get_xlim(), ax.get_ylim()]),
                        ]
                        ax.plot(lims, lims, 'r--', alpha=0.75, zorder=0, label="Perfect Prediction (y=x)")
                        ax.set_xlabel("Actual Lab Strength (MPa)")
                        ax.set_ylabel("Predicted Target Strength (MPa)")
                        ax.set_title("Lab Strength vs. Predicted Target Strength")
                        ax.legend()
                        ax.grid(True)
                        st.pyplot(fig)
                    else:
                        st.warning("Could not process the uploaded lab data CSV. Please check the file format, column names, and ensure it contains valid data.", icon="⚠️")
                except Exception as e:
                    st.error(f"Failed to read or process the lab data CSV file: {e}", icon="💥")
            else:
                st.info(
                    "Upload a lab data CSV in the sidebar to automatically compare CivilGPT's "
                    "target strength calculations against your real-world results.",
                    icon="ℹ️"
                )
            
    elif 'results' in st.session_state and not st.session_state.results["success"]:
        pass # Error message was already shown in the computation block

    elif not st.session_state.get('clarification_needed'):
        st.info("Enter your concrete requirements in the prompt box above, or switch to manual mode to specify parameters.", icon="👆")
        st.markdown("---")
        st.subheader("How It Works")
        st.markdown("""
        1.  **Input Requirements**: Describe your project needs (e.g., "M25 concrete for moderate exposure") or use the manual sidebar for detailed control.
        2.  **Select Purpose**: Choose your design purpose (e.g., 'Slab', 'Column') to enable purpose-specific optimization.
        3.  **IS Code Compliance**: The app generates dozens of candidate mixes, ensuring each one adheres to the durability and strength requirements of Indian Standards **IS 10262** and **IS 456**.
        4.  **Sustainability Optimization**: It then calculates the embodied carbon (CO₂e), cost, and 'Purpose-Fit' for every compliant mix.
        5.  **Best Mix Selection**: Finally, it presents the mix with the best **composite score** (or lowest CO₂/cost) alongside a standard OPC baseline for comparison.
        """)


if __name__ == "__main__":
    main()
